{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the multinomial Naive Bayes algorithm to train the computer to classify SMS messages using a dataset of 5,572 messages provided by Tiago A. Almeida and José María Gómez Hidalgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "Label    5572 non-null object\n",
      "SMS      5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86.6% of the dataset is non_spam and 13.4% is spam. The dataset has 5572 rows and two columns. We will now randomize so the new dataset is shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_new = data.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the randomized data into training (80% of data) and test (20% of data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "#Calulate the index to use for the split\n",
    "\n",
    "splitting_index = round(len(data) * 0.80)\n",
    "\n",
    "#Split the dataset into training and test sets\n",
    "training = data_new[:splitting_index]\n",
    "test = data_new[splitting_index:]\n",
    "\n",
    "#Show number of rows and columns for training and test\n",
    "print(training.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will reset the index labels for both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     0.86541\n",
      "spam    0.13459\n",
      "Name: Label, dtype: float64\n",
      "ham     0.868043\n",
      "spam    0.131957\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(training['Label'].value_counts(normalize=True))\n",
    "print(test['Label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the percentage of spam and ham messages in both sets is similar to the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index Label                                                SMS\n",
      "0   1078   ham                       Yep, by the pretty sculpture\n",
      "1   4028   ham      Yes, princess. Are you going to make me moan?\n",
      "2    958   ham                         Welp apparently he retired\n",
      "3   4642   ham                                            Havent.\n",
      "4   4674   ham  I forgot 2 ask ü all smth.. There's a card on ...\n",
      "   index Label                                                SMS\n",
      "0   2131   ham          Later i guess. I needa do mcat study too.\n",
      "1   3418   ham             But i haf enuff space got like 4 mb...\n",
      "2   3424  spam  Had your mobile 10 mths? Update to latest Oran...\n",
      "3   1538   ham  All sounds good. Fingers . Makes it difficult ...\n",
      "4   5393   ham  All done, all handed in. Don't know if mega sh...\n"
     ]
    }
   ],
   "source": [
    "print(training.head(5))\n",
    "print(test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index Label                                                SMS\n",
      "0   1078   ham                       yep  by the pretty sculpture\n",
      "1   4028   ham      yes  princess  are you going to make me moan \n",
      "2    958   ham                         welp apparently he retired\n",
      "3   4642   ham                                            havent \n",
      "4   4674   ham  i forgot 2 ask ü all smth   there s a card on ...\n",
      "   index Label                                                SMS\n",
      "0   2131   ham          later i guess  i needa do mcat study too \n",
      "1   3418   ham             but i haf enuff space got like 4 mb   \n",
      "2   3424  spam  had your mobile 10 mths  update to latest oran...\n",
      "3   1538   ham  all sounds good  fingers   makes it difficult ...\n",
      "4   5393   ham  all done  all handed in  don t know if mega sh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dataquest/system/env/python3/lib/python3.4/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/dataquest/system/env/python3/lib/python3.4/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/dataquest/system/env/python3/lib/python3.4/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/dataquest/system/env/python3/lib/python3.4/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "training['SMS'] = training['SMS'].str.replace('\\W', ' ')\n",
    "training['SMS'] = training['SMS'].str.lower()\n",
    "print(training.head(5))\n",
    "test['SMS'] = test['SMS'].str.replace('\\W', ' ')\n",
    "test['SMS'] = test['SMS'].str.lower()\n",
    "print(test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dataquest/system/env/python3/lib/python3.4/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7783\n"
     ]
    }
   ],
   "source": [
    "#Split the words in each message so they become\n",
    "#a list\n",
    "training['SMS'] = training['SMS'].str.split()\n",
    "\n",
    "vocabulary = []\n",
    "for msg in training['SMS']:\n",
    "    for word in msg:\n",
    "        vocabulary.append(word)   \n",
    "\n",
    "#Transform vocabulary into a set, thereby \n",
    "#removing duplicates. Then transform the set back to a \n",
    "#list\n",
    "vocabulary = list(set(vocabulary))\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7,783 unique words in the training dataet. Below we get the counts for each unique word in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform word_counts_per_sms into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data = word_counts_per_sms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1078</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4028</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>958</td>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4642</td>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4674</td>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Label                                                SMS  0  00  000  \\\n",
       "0   1078   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   4028   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2    958   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   4642   ham                                           [havent]  0   0    0   \n",
       "4   4674   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334 ...  zindgi  zoe  zogtorius  zouk  \\\n",
       "0       0             0     0            0 ...       0    0          0     0   \n",
       "1       0             0     0            0 ...       0    0          0     0   \n",
       "2       0             0     0            0 ...       0    0          0     0   \n",
       "3       0             0     0            0 ...       0    0          0     0   \n",
       "4       0             0     0            0 ...       0    0          0     0   \n",
       "\n",
       "   zyada  é  ú1  ü  〨ud  鈥  \n",
       "0      0  0   0  0    0  0  \n",
       "1      0  0   0  0    0  0  \n",
       "2      0  0   0  0    0  0  \n",
       "3      0  0   0  0    0  0  \n",
       "4      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7786 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_training = pd.concat([training, df1], axis=1)\n",
    "comb_training.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 7786)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_training.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate P(Spam) and P(Ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam messages:  600 Nonspam messages:  3858\n",
      "P(Spam):  0.13458950201884254\n",
      "P(Ham):  0.8654104979811574\n",
      "Nspam:  15190 Nham:  57237 Nvocabulary:  7783\n"
     ]
    }
   ],
   "source": [
    "spam_count = 0\n",
    "ham_count = 0\n",
    "spam_msgs = comb_training[comb_training['Label'] == 'spam']\n",
    "ham_msgs = comb_training[comb_training['Label'] == 'ham']\n",
    "for t in comb_training['Label']:\n",
    "    if t == 'spam':\n",
    "        spam_count +=1\n",
    "    elif t == 'ham':\n",
    "        ham_count +=1\n",
    "        \n",
    "print(\"Spam messages: \", spam_count, \"Nonspam messages: \", ham_count)        \n",
    "p_spam = spam_count / (spam_count + ham_count)\n",
    "print(\"P(Spam): \", p_spam)\n",
    "p_ham = ham_count / (spam_count + ham_count)\n",
    "print(\"P(Ham): \", p_ham)\n",
    "words_per_spam_msg = spam_msgs['SMS'].apply(len)\n",
    "N_spam = words_per_spam_msg.sum()\n",
    "words_per_ham_msg = ham_msgs['SMS'].apply(len)\n",
    "N_ham = words_per_ham_msg.sum()\n",
    "N_vocabulary = len(vocabulary)\n",
    "print(\"Nspam: \", N_spam, \"Nham: \", N_ham, \"Nvocabulary: \", N_vocabulary)\n",
    "\n",
    "#Add LaPlace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Initialize dictionaries for spam and ham\n",
    "spam_dict = {unique_word:0 for unique_word in vocabulary}\n",
    "ham_dict = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "#Spam and ham already isolated above\n",
    "for word in vocabulary:\n",
    "    count_word_given_spam = spam_msgs[word].sum()\n",
    "    p_word_given_spam = (count_word_given_spam + alpha) / (N_spam + (alpha * N_vocabulary))\n",
    "    spam_dict[word] = p_word_given_spam\n",
    "    \n",
    "    count_word_given_ham = ham_msgs[word].sum()\n",
    "    p_word_given_ham = (count_word_given_ham + alpha) / (N_ham + (alpha * N_vocabulary))\n",
    "    ham_dict[word] = p_word_given_ham\n",
    "        \n",
    "#print(spam_dict)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a spam filter function for filtering the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "#Initiate p_spam_given_message and p_ham_given_message\n",
    "#with an initial value\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "     \n",
    "    \n",
    "    \n",
    "    for word in message:\n",
    "        if word in spam_dict:\n",
    "            p_spam_given_message *= spam_dict[word]\n",
    "        if word in ham_dict:\n",
    "            p_ham_given_message *= ham_dict[word]\n",
    "   \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal probabilities, have a human classify this!')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n",
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "#Example messages to check classify function\n",
    "message1 = 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "message2 = \"Sounds good, Tom, then see u there\"\n",
    "\n",
    "#Classify the example messages above to check classify function\n",
    "check1 = classify(message1)\n",
    "check2 = classify(message2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first message (message1) is classified as spam and the second as ham. By inspection, this looks correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will measure the accuracy of our spam filter. But first we will customize the classify function for our test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in spam_dict:\n",
    "            p_spam_given_message *= spam_dict[word]\n",
    "\n",
    "        if word in ham_dict:\n",
    "            p_ham_given_message *= ham_dict[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the classify_test_set function, we will predict spam or ham for each message in our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dataquest/system/env/python3/lib/python3.4/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2131</td>\n",
       "      <td>ham</td>\n",
       "      <td>later i guess  i needa do mcat study too</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3418</td>\n",
       "      <td>ham</td>\n",
       "      <td>but i haf enuff space got like 4 mb</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3424</td>\n",
       "      <td>spam</td>\n",
       "      <td>had your mobile 10 mths  update to latest oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1538</td>\n",
       "      <td>ham</td>\n",
       "      <td>all sounds good  fingers   makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5393</td>\n",
       "      <td>ham</td>\n",
       "      <td>all done  all handed in  don t know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Label                                                SMS predicted\n",
       "0   2131   ham          later i guess  i needa do mcat study too        ham\n",
       "1   3418   ham             but i haf enuff space got like 4 mb          ham\n",
       "2   3424  spam  had your mobile 10 mths  update to latest oran...      spam\n",
       "3   1538   ham  all sounds good  fingers   makes it difficult ...       ham\n",
       "4   5393   ham  all done  all handed in  don t know if mega sh...       ham"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['predicted'] = test['SMS'].apply(classify_test_set)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9874326750448833\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test['SMS'])\n",
    "#print(total)\n",
    "\n",
    "for row in test.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 98.7%. So our spam filter is highly effective!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
